{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb1cf11-207b-4536-aab8-ee903c8477e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from src.basenet import BaseNetDatabase\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67e152-ef99-4b1c-838b-f52895312a25",
   "metadata": {},
   "source": [
    "# BaseNetDatabase\n",
    "\n",
    "## Advanced use tutorial\n",
    "\n",
    "In this JuPyter Notebook we will learn further uses and specifications of the ``BaseNetDatabase`` Class.\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. About ``BaseNetDatabase``.\n",
    "2. Construction.\n",
    "    1. Build from raw data.\n",
    "    2. Build from ``numpy.array`` class.\n",
    "    3. Build from ``tensorflow.data.Dataset`` class.\n",
    "    4. Build from ``pandas.DataFrame`` class.\n",
    "3. Save and load databases.\n",
    "4. Split databases.\n",
    "5. Merge databases.\n",
    "6. Specify train, validation and test datasets explicitly.\n",
    "\n",
    "## 1. About BaseNetDatabase.\n",
    "\n",
    "The BaseNetDatabase is an Python Class that contains the relevant information for the API to work with a Database. The Datasets are stored in ``np.ndarrays``.\n",
    "\n",
    "    The BaseNetDatabase class converts a set of inputs (x) and solutions (y) into the API wrapper database.\n",
    "    The BaseNetDatabase will create a new set of attributes from the database randomly:\n",
    "\n",
    "        *   xtrain: A subset of (x) with the train inputs of the network.\n",
    "        *   ytrain: A subset of (y) with the train solutions of the network.\n",
    "        *   xval: A subset of (x) with the training validation inputs of the network.\n",
    "        *   yval: A subset of (y) with the training validation solutions of the network.\n",
    "        *   xtest: A subset of (x) with excluded inputs of the network; for future testing.\n",
    "        *   ytest: A subset of (y) with excluded solutions of the network; for future testing.\n",
    "\n",
    "        *   dtype: Data type of the input data (x) and output data (y) in a tuple of strings (x_dtype, y_dtype).\n",
    "        *   name: Name of the database.\n",
    "        *   distribution: Train, validation and test distribution of the input database.\n",
    "        *   batch_size: Current batch size of the database.\n",
    "        *   size: The size of the database (train, validation , test).\n",
    "\n",
    "    The BaseNetDatabase can be loaded and saved with its own methods.\n",
    "    \n",
    "## 2. Construction.\n",
    "\n",
    "To build a BaseNetDatabase we usually give it two parameters: 'x' and 'y'. 'x' contains the input values of the model and 'y' contains the solutions.\n",
    "\n",
    "        BaseNetDatabase(x, y=None, \n",
    "                        distribution: dict = None, \n",
    "                        name='unnamed_database', \n",
    "                        batch_size: int = None,\n",
    "                        rescale: float = 1.0, \n",
    "                        dtype: tuple[str, str] = ('float', 'float'), \n",
    "                        bits: tuple[int, int] = (32, 32))\n",
    "        \n",
    "        This class builds a BaseNetDatabase, compatible with the NetBase API.\n",
    "        :x: Inputs of the dataset.\n",
    "        :y: Solutions of the dataset.\n",
    "        :distribution: The distribution of the datasets, default: {'train': 70, 'val': 20, 'test': 10}\n",
    "        :name: The database name.\n",
    "        :batch_size: Custom batch size for training.\n",
    "        :rescale: Rescale factor, all the values in x are divided by this factor, in case rescale is needed.\n",
    "        :dtype: Data type of the dataset. ('input', 'output') (x, y)\n",
    "        :bits: Bits used for the data type. ('input', 'output') (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34330b07-c513-4be7-8dc7-88025ab45958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, \n",
    "             x, y=None, distribution: dict = None, name='unnamed_database', batch_size: int = None,\n",
    "             rescale: float = 1.0, dtype: tuple[str, str] = ('float', 'float'), bits: tuple[int, int] = (32, 32)):\n",
    "    [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444cc251-3362-40f8-a90a-c94ac1aa17ef",
   "metadata": {},
   "source": [
    "#### 2.1. Build from raw data.\n",
    "\n",
    "You can build your model from raw data. We will create a random Dataset, not very large. Where 'x' will be random data and 'y' random solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d60746bc-0311-493d-8ed7-35368031dc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.9502457351725069, 0.8436442369903798, 0.23317060471725104],\n",
       "  [0.5792361744164586, 0.25472658344652943, 0.14503465503541246],\n",
       "  [0.7727576933534599, 0.9214589688527682, 0.7578435485725693],\n",
       "  [0.8843969141157557, 0.9177107612724367, 0.10917853819455048],\n",
       "  [0.6303568906101952, 0.7995476070335449, 0.1094439008630681],\n",
       "  [0.6147708775678057, 0.8298626546772362, 0.851563057821567],\n",
       "  [0.7335646932915939, 0.8592629871967927, 0.8827126794747593],\n",
       "  [0.47398027733282877, 0.4067264792280043, 0.2600070460463293],\n",
       "  [0.9914459488212445, 0.287847889984154, 0.9885820498408971],\n",
       "  [0.6330518709648455, 0.3404476138595036, 0.012274734441484525]],\n",
       " [6, 5, 4, 8, 1, 7, 8, 4, 3, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_random_dataset(x_dim, y_dim):\n",
    "    return [[random.random() for _ in range(x_dim)] for _ in range(y_dim)], [random.randint(0, 10) for _ in range(y_dim)]\n",
    "\n",
    "x, y = create_random_dataset(3, 10)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b169d-f2fd-4efe-8e95-b78b7bdadfa4",
   "metadata": {},
   "source": [
    "We can create a distribution from training, validation and test and a name for the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6bdd7a-f933-4b72-a0c2-b23ef3c7bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {'train': 60, 'val': 20, 'test': 20}\n",
    "name = 'random_database'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fd1c8-c478-4131-9d49-ef468de342e2",
   "metadata": {},
   "source": [
    "The datatypes are also a useful parameter, we will define 'x' as float32 and 'y' as int8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8111c152-0ab8-4c74-b139-f0ac05e989ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = ('float', 'int')\n",
    "bits = (32, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047298b3-8d78-40c0-98e1-e4fa65aaaf24",
   "metadata": {},
   "source": [
    "The rescale parameter is a number which will divide all the data in 'x'. We will set it to 2, so our data will be between [0, 0.5] instead of [0, 1] with default rescale. \n",
    "\n",
    "This is useful, for example, for images, where the data is usually in the range of [0, 255], so a recale of 255 is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4dfce4c-3d19-403d-a434-3978850d5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58429289-4dc5-4322-89ce-cb4ec51d7169",
   "metadata": {},
   "source": [
    "The batch size is a parameter that will be used by our model. This batches are a group of data that will be evaluated as a whole in the training process of Deep Learning models. Refer to the Machine Learning theory to undertand more abour this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b98934-43ec-4d09-b78e-bba6dcf9fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01279929-51ee-4505-a7a3-703b21195459",
   "metadata": {},
   "source": [
    "Now we build our database with our specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c02f36-36fb-4b8d-aa4f-1beecb4caa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseNetDatabase with 10 instances."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_db = BaseNetDatabase(x, y, \n",
    "                        distribution=distribution, \n",
    "                        name=name, \n",
    "                        batch_size=batch_size,\n",
    "                        rescale=rescale, \n",
    "                        dtype=dtype, \n",
    "                        bits=bits)\n",
    "my_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583462d3-d59d-466c-9b35-af4aaa6a0ed3",
   "metadata": {},
   "source": [
    "The default representation of the model will show you the instances. Now let's see the Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773d22e5-1395-49ee-b8c2-69506f078a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.31517845 0.3997738  0.05472195]\n",
      " [0.23699014 0.20336324 0.13000353]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.47512287 0.42182213 0.1165853 ]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.44219846 0.4588554  0.05458927]\n",
      " [0.38637885 0.46072948 0.37892178]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.30738544 0.41493133 0.42578152]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for dataset in ('train', 'val', 'test'):\n",
    "    print('')\n",
    "    for element in ('x', 'y'):\n",
    "        fulldataset = f'{element}{dataset}'\n",
    "        print(f'my_db.{fulldataset}:\\n{getattr(my_db, f\"{fulldataset}\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e07a2-f311-49fa-828b-1f54be18f8a2",
   "metadata": {},
   "source": [
    "As you can see, the 'y' values are automatically binarized. This is because the Deep Learning models do not work with integers, but with probability. Each output of the model will represent a probability that each value belongs to the reference element. In this case, we had integers between [0, 10], that is why there are 10 elements in each value of the 'y' datasets.\n",
    "\n",
    "We can also see that the values of the original data is halved due to the \n",
    "\n",
    "Note that this is a feature that cannot predict the total range of your values, it takes the maximum to binarize, so feel free to binarize your input beforehand (which is slightly recomended).\n",
    "\n",
    "We also check that the 'y' values are of type ``int8``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986e5cfc-e6b0-4f5c-ae60-6987f94a1339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "print('Type of y:', my_db.ytest.dtype, '\\nType of x:', my_db.xtest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1423c1-7b43-4076-8eed-aa6e63d5d62c",
   "metadata": {},
   "source": [
    "The batch size is automatically assigned if it is not provided. The batch size that will be assigned depends on the number of instances provided for training and follows the function:\n",
    "\n",
    "     batch_size = 2^round(log_2(len(xtrain) / 256))\n",
    "     \n",
    "Which is similar to:\n",
    "\n",
    "        batch_size = round(len(xtrain) / 256)  # This is not the function.\n",
    "    \n",
    "But the last does not provide a number that can be expresed as a power of 2.\n",
    "\n",
    "This is a good way to estimate your batch size, but it can be different for every problem, so it is recomended to be defined beforehand.\n",
    "\n",
    "If we used auto-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c844748c-516e-408e-a046-9cdbf36a25cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size:\t 2 \n",
      "Autobatch:\t 1\n"
     ]
    }
   ],
   "source": [
    "my_db_autobatch = BaseNetDatabase(x, y, \n",
    "                                  distribution=distribution, \n",
    "                                  name=name,\n",
    "                                  rescale=rescale, \n",
    "                                  dtype=dtype, \n",
    "                                  bits=bits)\n",
    "print('\\nBatch size:\\t', my_db.batch_size, '\\nAutobatch:\\t', my_db_autobatch.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10232ca-859a-4e27-96a7-82dbeef65cb6",
   "metadata": {},
   "source": [
    "#### 2.1. Build from numpy data.\n",
    "\n",
    "You can build your database from different sources. We will rebuild our dataset as a numpy array and feed it to the constructor, as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1eca22-3788-43ac-b9a8-0723e54e00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.array(x)\n",
    "y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49a779-71a7-40aa-b02e-b37f04191a0a",
   "metadata": {},
   "source": [
    "Now we call the constructor as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a6deed-07b7-4386-a57e-04dfb5fbb0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.31517845 0.3997738  0.05472195]\n",
      " [0.44219846 0.4588554  0.05458927]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.47512287 0.42182213 0.1165853 ]\n",
      " [0.30738544 0.41493133 0.42578152]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "def build_and_print_db(x_v, y_v):\n",
    "    my_db = BaseNetDatabase(x_v, y_v, \n",
    "                            distribution=distribution, \n",
    "                            name=name, \n",
    "                            batch_size=batch_size,\n",
    "                            rescale=rescale, \n",
    "                            dtype=dtype, \n",
    "                            bits=bits)\n",
    "    print_db(my_db)\n",
    "    \n",
    "def print_db(my_db):\n",
    "    for dataset in ('train', 'val', 'test'):\n",
    "        print('')\n",
    "        for element in ('x', 'y'):\n",
    "            fulldataset = f'{element}{dataset}'\n",
    "            print(f'my_db.{fulldataset}:\\n{getattr(my_db, f\"{fulldataset}\")}')\n",
    "    print('\\nType of y:', my_db.ytest.dtype, '\\nType of x:', my_db.xtest.dtype)\n",
    "            \n",
    "build_and_print_db(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6be6ee-9abd-4ac2-96ad-505555a7b5ef",
   "metadata": {},
   "source": [
    "As we can see, it is the same result, but randomly shuffled.\n",
    "\n",
    "#### 2.3. Build from ``tensorflow.data.Dataset`` class.\n",
    "\n",
    "If some time you used TensorFlow, you would have notice it has a special way to store datasets. The API automatically creates a BaseNetDataset from the given ``tensorflow.data.Dataset`` as 'x' if you set up 'y' to a tuple to idenfity 'x' and 'y' (default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ab2f42-20e2-40a9-a54b-97a8bab23ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec={'x_values': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'y_values': TensorSpec(shape=(), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_is = 'x_values'\n",
    "y_is = 'y_values'\n",
    "\n",
    "tfds = tf.data.Dataset.from_tensor_slices({x_is: x, y_is: y})\n",
    "tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7235e94-6230-4d48-bc4f-ba825c594717",
   "metadata": {},
   "source": [
    "And build the BaseNetDatabase with the arguments:\n",
    "\n",
    "        my_db = BaseNetDatabase(tfds, ('x_values', 'y_values'), \n",
    "                               distribution=distribution, \n",
    "                               name=name, \n",
    "                               batch_size=batch_size,\n",
    "                               rescale=rescale, \n",
    "                               dtype=dtype, \n",
    "                               bits=bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee054248-89ca-4082-862d-9aa2684cc910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.28961807 0.1273633  0.07251733]\n",
      " [0.47512287 0.42182213 0.1165853 ]\n",
      " [0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]\n",
      " [0.30738544 0.41493133 0.42578152]\n",
      " [0.38637885 0.46072948 0.37892178]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.36678234 0.4296315  0.44135633]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "my_db = BaseNetDatabase(tfds, ('x_values', 'y_values'), \n",
    "                       distribution=distribution, \n",
    "                       name=name, \n",
    "                       batch_size=batch_size,\n",
    "                       rescale=rescale, \n",
    "                       dtype=dtype, \n",
    "                       bits=bits)\n",
    "print_db(my_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb96f9-ea2c-47ce-b42e-235d8f4372ce",
   "metadata": {},
   "source": [
    "Te became the same database as we did from raw data!\n",
    "\n",
    "#### 2.4. Build from ``pandas.DataFrame`` class.\n",
    "\n",
    "If some time you used Pandas, you would have notice it has a special way to store datasets (in pandas.DataFrames). The API automatically creates a BaseNetDataset from the given ``pandas.DataFrame`` as long as you specify the name of the columns that identify 'y', in a string. The remaining parts of the DataFrame will be 'x'. Let's create the DataFrame from a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe53c2b0-c69e-40f9-b0e4-093cc21d93b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>y_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950246</td>\n",
       "      <td>0.843644</td>\n",
       "      <td>0.233171</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.579236</td>\n",
       "      <td>0.254727</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772758</td>\n",
       "      <td>0.921459</td>\n",
       "      <td>0.757844</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884397</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>0.109179</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630357</td>\n",
       "      <td>0.799548</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.614771</td>\n",
       "      <td>0.829863</td>\n",
       "      <td>0.851563</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.733565</td>\n",
       "      <td>0.859263</td>\n",
       "      <td>0.882713</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.473980</td>\n",
       "      <td>0.406726</td>\n",
       "      <td>0.260007</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.991446</td>\n",
       "      <td>0.287848</td>\n",
       "      <td>0.988582</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.633052</td>\n",
       "      <td>0.340448</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c  y_column\n",
       "0  0.950246  0.843644  0.233171       6.0\n",
       "1  0.579236  0.254727  0.145035       5.0\n",
       "2  0.772758  0.921459  0.757844       4.0\n",
       "3  0.884397  0.917711  0.109179       8.0\n",
       "4  0.630357  0.799548  0.109444       1.0\n",
       "5  0.614771  0.829863  0.851563       7.0\n",
       "6  0.733565  0.859263  0.882713       8.0\n",
       "7  0.473980  0.406726  0.260007       4.0\n",
       "8  0.991446  0.287848  0.988582       3.0\n",
       "9  0.633052  0.340448  0.012275       2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['a', 'b', 'c', 'y_column']\n",
    "x_np = np.array(x)\n",
    "y_np = np.array([y], dtype='int8').T\n",
    "np_data = np.concatenate([x_np, y_np], axis=1)\n",
    "df = pd.DataFrame(data=np_data, columns=column_names)\n",
    "df.head(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84bf36-d1cb-4470-9664-da62c3bd1264",
   "metadata": {},
   "source": [
    "Now, it's time to build pand print the model with:\n",
    "\n",
    "    my_db = BaseNetDatabase(df, 'y_column', \n",
    "                            distribution=distribution, \n",
    "                            name=name, \n",
    "                            batch_size=batch_size,\n",
    "                            rescale=rescale, \n",
    "                            dtype=dtype, \n",
    "                            bits=bits)\n",
    "                            \n",
    "Note: If you do not specify a 'y' value or set it to None, the 'y' value will be the last column of the DataFrame by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95503431-ac86-4507-b333-e96e9dc849dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "my_db = BaseNetDatabase(df, 'y_column', \n",
    "                        distribution=distribution, \n",
    "                        name=name, \n",
    "                        batch_size=batch_size,\n",
    "                        rescale=rescale, \n",
    "                        dtype=dtype, \n",
    "                        bits=bits)\n",
    "print_db(my_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79359e9b-9ddf-4dba-9af2-20666cb7f4dc",
   "metadata": {},
   "source": [
    "#### 3. Save and load databases.\n",
    "\n",
    "The way to save and load databases is using the ``.save()`` and ``.load()`` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7017b0-4d52-4c71-b1d9-72081ccec958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_db.save('./my_test_db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fcabf5-0787-4e44-b54b-87458799adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "my_loaded_db = BaseNetDatabase.load('./my_test_db.db')\n",
    "print_db(my_loaded_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb3388-9d8f-4590-a1ca-e49e6425ca33",
   "metadata": {},
   "source": [
    "#### 4. Split databases.\n",
    "\n",
    "You can split BaseNetDatabases calling the method ``split()`` or dividing by an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71cebdc1-6a22-4696-95ac-8fb6e9dd3803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First database: =======================================\n",
      "\n",
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n",
      "\n",
      "\n",
      "Second database: =======================================\n",
      "\n",
      "\n",
      "my_db.xtrain:\n",
      "[[0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "splitted_db = my_db / 2\n",
    "print('First database: =======================================\\n')\n",
    "print_db(splitted_db[0])\n",
    "print('\\n\\nSecond database: =======================================\\n')\n",
    "print_db(splitted_db[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ea967df-6e63-4e8d-a663-e3ddf30cb591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First database: =======================================\n",
      "\n",
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n",
      "\n",
      "\n",
      "Second database: =======================================\n",
      "\n",
      "\n",
      "my_db.xtrain:\n",
      "[[0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "splitted_db = my_db.split(2)\n",
    "print('First database: =======================================\\n')\n",
    "print_db(splitted_db[0])\n",
    "print('\\n\\nSecond database: =======================================\\n')\n",
    "print_db(splitted_db[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ad821-c407-4779-9e38-a43cf085393c",
   "metadata": {},
   "source": [
    "#### 5. Merge databases.\n",
    "\n",
    "The oposite of the ``split()`` method is the ``merge()`` method. You can merge two BaseNetDatabases into one just by calling ``merge()`` or using the operator ``+``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a1aa30-f92d-464f-9eff-2eb5e8841cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "reconstructed_db = splitted_db[0] + splitted_db[1]\n",
    "print_db(reconstructed_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0cbea0-47b0-4027-b46b-ade6db62a96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.49572298 0.14392394 0.49429104]\n",
      " [0.36678234 0.4296315  0.44135633]\n",
      " [0.47512287 0.42182213 0.1165853 ]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytrain:\n",
      "[[0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.30738544 0.41493133 0.42578152]]\n",
      "my_db.yval:\n",
      "[[0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytest:\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0]]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "reconstructed_db = splitted_db[0].merge(splitted_db[1])\n",
    "print_db(reconstructed_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00797c26-c85f-438e-a7db-fec045baa0cc",
   "metadata": {},
   "source": [
    "#### 6. Specify train, validation and test datasets explicitly.\n",
    "\n",
    "If you dont feel conftable about the BaseNetDatabase is randomly shuffling your data into train, validation and test datasets from a single block of data, you can manually specify the datasets to the ``from_datasets()`` method.\n",
    "\n",
    "    my_manual_db = BaseNetDatabase.from_datasets(train=(train_x, train_y), val=(val_x, val_y), test=(test_x, test_y), \n",
    "                                                 batch_size=batch_size,\n",
    "                                                 name=name, dtype=dtype,\n",
    "                                                 bits=bits, rescale=rescale)\n",
    "                                                 \n",
    "Note: When you introduce the datasets manually, the binarization and normalization is not performed, as we suppose that you did it manually and your datasets are correctly pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6c744ab-573a-4ac4-bc54-f1a6affa4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition:\n",
    "@staticmethod\n",
    "def from_datasets(train: tuple, val: tuple, test: tuple, batch_size: int = None,\n",
    "                  name: str = 'unnamed_database', dtype: tuple[str, str] = ('float', 'float'),\n",
    "                  bits: tuple[int, int] = (32, 32), rescale: float = 1.):\n",
    "    [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b0f39ad-4423-448f-9f25-cf739b6f98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my_db.xtrain:\n",
      "[[0.47512287 0.42182213 0.1165853 ]\n",
      " [0.28961807 0.1273633  0.07251733]\n",
      " [0.38637885 0.46072948 0.37892178]\n",
      " [0.44219846 0.4588554  0.05458927]\n",
      " [0.31517845 0.3997738  0.05472195]]\n",
      "my_db.ytrain:\n",
      "[6 5 4 8 1]\n",
      "\n",
      "my_db.xval:\n",
      "[[0.30738544 0.41493133 0.42578152]\n",
      " [0.36678234 0.4296315  0.44135633]]\n",
      "my_db.yval:\n",
      "[7 8]\n",
      "\n",
      "my_db.xtest:\n",
      "[[0.23699014 0.20336324 0.13000353]\n",
      " [0.49572298 0.14392394 0.49429104]\n",
      " [0.31652594 0.1702238  0.00613737]]\n",
      "my_db.ytest:\n",
      "[4 3 2]\n",
      "\n",
      "Type of y: int8 \n",
      "Type of x: float32\n"
     ]
    }
   ],
   "source": [
    "train_x = x[0:5]\n",
    "train_y = y[0:5]\n",
    "val_x = x[5:7]\n",
    "val_y = y[5:7]\n",
    "test_x = x[7:]\n",
    "test_y = y[7:]\n",
    "my_manual_db = BaseNetDatabase.from_datasets(train=(train_x, train_y), val=(val_x, val_y), test=(test_x, test_y), \n",
    "                                             batch_size=batch_size,\n",
    "                                             name=name, dtype=dtype,\n",
    "                                             bits=bits, rescale=rescale)\n",
    "print_db(my_manual_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73e165-bd88-4cf6-bb02-993334b01129",
   "metadata": {},
   "source": [
    "As you can see, there is no binarization of the 'y' values.\n",
    "\n",
    "You reached the end of the advanced BaseNetDatabase tutorial. Crongratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
