window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "basenet", "modulename": "basenet", "type": "module", "doc": "<h1 id=\"basenet-a-simpler-way-to-build-ai-models\">BaseNet: A simpler way to build AI models.</h1>\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/iTzAlver/basenet_api/main/doc/multimedia/basenet_logo.png\">\n</p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/iTzAlver/basenet_api/blob/main/LICENSE\">\n        <img src=\"https://img.shields.io/github/license/iTzAlver/basenet_api?color=purple&style=plastic\" /></a>\n    <a href=\"https://github.com/iTzAlver/basenet_api/tree/main/test\">\n        <img src=\"https://img.shields.io/badge/tests-passed-green?color=green&style=plastic\" /></a>\n    <a href=\"https://github.com/iTzAlver/basenet_api/blob/main/requirements.txt\">\n        <img src=\"https://img.shields.io/badge/requirements-pypi-red?color=red&style=plastic\" /></a>\n    <a href=\"https://htmlpreview.github.io/?https://github.com/iTzAlver/basenet_api/blob/main/doc/basenet.html\">\n        <img src=\"https://img.shields.io/badge/doc-available-green?color=yellow&style=plastic\" /></a>\n    <a href=\"https://github.com/iTzAlver/BaseNet-API/releases/tag/1.5.0-release\">\n        <img src=\"https://img.shields.io/badge/release-1.5.0-white?color=white&style=plastic\" /></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://www.tensorflow.org/\">\n        <img src=\"https://img.shields.io/badge/dependencies-tensorflow-red?color=orange&style=for-the-badge\" /></a>\n    <a href=\"https://keras.io/\">\n        <img src=\"https://img.shields.io/badge/dependencies-keras-red?color=red&style=for-the-badge\" /></a>\n</p>\n\n<h1 id=\"basenet-api-package-150\">Basenet API Package - 1.5.0</h1>\n\n<p>This package implements an API over Keras and Tensorflow to build Deep Learning models easily without losing the\nframework flexibility. BaseNet API tries to implement almost everything from a few lines of code.</p>\n\n<h2 id=\"about\">About</h2>\n\n<pre><code>Author: A.Palomo-Alonso (a.palomo@uah.es)\nUniversidad de Alcal\u00e1.\nEscuela Polit\u00e9cnica Superior.\nDepartamento de Teor\u00eda De la Se\u00f1al y Comunicaciones (TDSC).\nISDEFE Chair of Research.\n</code></pre>\n\n<h2 id=\"features\">Features</h2>\n\n<ul>\n<li><strong>Feature 1:</strong> Real-time logging.</li>\n<li><strong>Feature 2:</strong> Database train, validation and test automatic and random segmentation.</li>\n<li><strong>Feature 3:</strong> Real multiprocessing training process.</li>\n<li><strong>Feature 4:</strong> Automatic and custom GPU usage.</li>\n<li><strong>Feature 5:</strong> Easy-to-use classes.</li>\n<li><strong>Feature 6:</strong> Model merging.</li>\n<li><strong>Feature 7:</strong> Multiple model inputs.</li>\n<li><strong>Feature 8:</strong> API documentation.</li>\n<li><strong>Feature 9:</strong> Python Packaging and PyPi indexing.</li>\n<li><strong>Feature 10:</strong> Automatic GPU configuration and assignment.</li>\n</ul>\n\n<h2 id=\"basic-and-fast-usage\">Basic and fast usage</h2>\n\n<h3 id=\"basenetdataset\">BaseNetDataset</h3>\n\n<p>BaseNetDatabase is an easy-to-use database wrapper for the API. You can build your \ndatabase with the BaseNetDatabase class.</p>\n\n<h3 id=\"example-of-building-a-basenetdataset\">Example of building a BaseNetDataset.</h3>\n\n<pre><code>from basenet_api import BaseNetDatabase\n\nmy_data_x, my_data_y = load_my_data()\nprint(my_data_y)\n\n#    &gt; array([[0.], [1.], ...], dtype=float32)\n\nprint(my_data_x)\n\n#    &gt; array([[255., 0., 255., ..., dtype=float32)\n\ndistribution = {'train': 60, 'test': 5, 'val': 35}\nmydb = BaseNetDatabase(my_data_x, my_data_y, \n                       distribution=distribution)\n\nprint(mydb)\n\n#    &gt; BaseNetDatabase with 32000 instances.\n\nmydb.save('./mydb.db')\n</code></pre>\n\n<h3 id=\"basenetcompiler\">BaseNetCompiler</h3>\n\n<p>BaseNetCompiler takes the model architecture and builds a BaseNetModel with the given\nparameters. You can build your BaseNetCompiler from Python code only or a .yaml file.</p>\n\n<h3 id=\"example-of-building-a-basenetcompiler-from-python-code-only\">Example of building a BaseNetCompiler from Python code only.</h3>\n\n<pre><code>from basenet_api import BaseNetDatabase, BaseNetCompiler\n\nmydb = BaseNetDatabase.load('./mydb.db')\nprint(mydb)\n\n#    &gt; BaseNetDatabase with 32000 instances.\n\nlayers = [\n    {'Dense': ((255,), {})},\n    {'Dense': ((64,), {'activation': 'relu'})},\n    {'Dropout': ((0.5,), {})}\n]\n\nmy_devs = BaseNetCompiler.show_devs()\nprint(my_devs)\n\n#    &gt; {'/device:CPU:0': 'Idle', \n#       '/device:GPU:0': 'Train'}\n\nmy_first_model = BaseNetCompiler(\n    io_shape=((8,), 8), \n    compile_options={'loss': 'mean_squared_error', 'optimizer': 'adam'}, \n    devices=my_devs, \n    layers=layers,\n    name='my_first_model'\n).compile()\n\nmy_first_model.add_database(mydb)\n</code></pre>\n\n<p>You can also use the BaseNetModel.add() method to add layers.</p>\n\n<pre><code>my_first_compiler = BaseNetCompiler(\n    io_shape=((8,), 8), \n    compile_options={'loss': 'mean_squared_error', 'optimizer': 'adam'}, \n    devices=my_devs,\n    name='my_first_model'\n)\nfor layer in layers:\n    my_first_compiler.add(layer)\n\nmy_first_model = my_first_compiler.compile()\n</code></pre>\n\n<p>You can also load the database from the path.</p>\n\n<pre><code>my_fitst_model.add_database('./mydb.db')\n</code></pre>\n\n<h3 id=\"example-of-building-a-basenetcompiler-from-yaml-file\">Example of building a BaseNetCompiler from .yaml file.</h3>\n\n<p>Suppose you have a <code>.yaml</code> file in the <code>./my_model.yaml</code> location with\nthe proper format you can load your compiler with the method <code>BaseNetCompiler().build_from_yaml(yaml_path)</code>\nand omit the process of loading the parameters into the compiler manually.</p>\n\n<pre><code>from basenet_api import BaseNetDatabase, BaseNetCompiler\n\nmydb = BaseNetDatabase.load('./mydb.db')\nprint(mydb)\n\n#    &gt; BaseNetDatabase with 32000 instances.\n\nyaml_path = './my_model.yaml'\n\nmy_first_model = BaseNetCompiler.build_from_yaml(yaml_path).compile()\nmy_first_model.add_database(mydb)\n</code></pre>\n\n<p>An example of <code>.yaml</code> to replicate the same model as in the section \n<code>Building a BaseNetCompiler from Python code only.</code>, the <code>.yaml</code> file will be the following:</p>\n\n<pre><code>compiler:\n  name: \"my_first_model\"\n  input_shape:\n    - 8\n  output_shape: 8\n\n  compile_options:\n    loss: \"mean_squared_error\"\n    optimizer: \"adam\"\n\n  devices:\n    - cpu:\n        name: \"/device:CPU:0\"\n        state: \"Idle\"\n    - gpu:\n        name: \"/device:GPU:0\"\n        state: \"Train\"\n\n  layers:\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 128\n        options:\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 128\n        options:\n          - option:\n              name: \"activation\"\n              value: \"relu\"\n\n    - layer:\n        name: \"Dropout\"\n        shape:\n          - 0.5\n        options:\n</code></pre>\n\n<p>If you want to learn more about building a model from a <code>.yaml</code> file, please, check the API \n<a href=\"https://htmlpreview.github.io/?https://github.com/iTzAlver/basenet_api/blob/main/doc/basenet.html\">documentation</a>.</p>\n\n<h3 id=\"example-of-usage-of-the-basenetmodel\">Example of usage of the BaseNetModel.</h3>\n\n<p>Once you build and compile a <code>BaseNetModel</code> with a <code>BaseNetCompiler.compile()</code> method, you can make use of all the\nmethods that the BaseNetModel provides:</p>\n\n<ul>\n<li><code>BaseNetModel.load()</code>: This method loads a tf.keras.model and the compiler from the given path.</li>\n<li><code>BaseNetModel.save()</code>: This method saves a tf.keras.model and the compiler into the given path.</li>\n<li><code>BaseNetModel.print()</code>: This method renders a <code>.png</code> image of the model into the given path.</li>\n<li><code>BaseNetModel.add_database()</code>: The <code>BaseNetModel</code> contains a breech of databases. It is a list with all the loaded\ndatabases previously. This method adds a database from a path or from a <code>BaseNetDatabase</code> object.</li>\n<li><code>BaseNetModel.predict()</code>: Performs a prediction given an input.</li>\n<li><code>BaseNetModel.evaluate()</code>: Evaluates the model with the pointed database test subset.</li>\n<li><code>BaseNetModel.fit()</code>: Trains the model with the pointed database.</li>\n<li><code>BaseNetModel.call()</code>: Merges two models into one. It can be used as a function.</li>\n</ul>\n\n<h4 id=\"printing-and-fitting-a-model\">Printing and fitting a model.</h4>\n\n<pre><code>from basenet_api import BaseNetDatabase, BaseNetCompiler\n\nmydb = BaseNetDatabase.load('./mydb.db')\nmy_first_model = BaseNetCompiler.build_from_yaml('./my_model.yaml').compile()\nmy_first_model.add_database(mydb)\n\n# Select database with index 0.\nmy_first_model.fit(0, epochs=6, tensorboard=False)\n\n#    &gt;   Tensorflow fitting info vomiting.\n\n# Print the model.\nmy_first_model.print('./my_model.png')\n</code></pre>\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/iTzAlver/basenet_api/main/doc/multimedia/example_model.png\">\n</p>\n\n<h4 id=\"fitting-a-model-in-other-process\">Fitting a model in other process.</h4>\n\n<p><strong>Important:</strong> Debugging is not working properly when fitting a new process.</p>\n\n<p>Imagine working on a GUI. The training process of your model implemented on your\nGUI will block the parent process. The API implements a solution. Just activate\n<code>avoid_lock=True</code> in the <code>BaseNetModel.fit()</code> method and check the results whenever you want.</p>\n\n<pre><code>from basenet_api import BaseNetDatabase, BaseNetCompiler\n\nmydb = BaseNetDatabase.load('./mydb.db')\nmy_first_model = BaseNetCompiler.build_from_yaml('./my_model.yaml').compile()\nmy_first_model.add_database(mydb)\n\n# Select database with index 0.\nmy_results = my_first_model.fit(0, epochs=6, tensorboard=False, avoid_lock=True)\n\nwhile my_results.is_training:\n    do_my_main_activity(update_gui, collect_data, run_server, or_whatever)\n    current_loss_curve = my_results.get()\n\n# my_first_model.recover() Use it in versions &lt; 1.5.0.\n\nkeep_doing_my_main_activity(update_gui, collect_data, run_server, or_whatever)\n</code></pre>\n\n<p><code>OutDated</code>:\nNote that if you don't make use of the method <code>BaseNetModel.recover()</code> the model will be empty as\nthe trained model is bypassed by the child process until the parent process is able to recover the trained model.</p>\n\n<p><code>From &gt;= 1.5.0</code>: The model recovers itself, there is no need (or ways) to recover it manually.</p>\n\n<h4 id=\"using-tensorboard\">Using Tensorboard.</h4>\n\n<p>The API also implements Tensorboard automatic opening and initialization. You can see the training process and keras\napp in real time while training.</p>\n\n<pre><code>my_first_model.fit(0, epochs=6, tensorboard=True)\n</code></pre>\n\n<h4 id=\"merging-two-models-into-one-with-several-inputs\">Merging two models into one with several inputs.</h4>\n\n<p>You can merge two BaseNetModels by calling the object as a function:</p>\n\n<pre><code>from basenet_api import BaseNetDatabase, BaseNetCompiler\nmydb = BaseNetDatabase.load('./mydb.db')\nmy_first_model = BaseNetCompiler.build_from_yaml('./my_model.yaml', verbose=True).compile()\nmy_second_model = BaseNetCompiler.build_from_yaml('./my_model_2.yaml', verbose=True).compile()\nmy_first_model.add_database(mydb)\n\nmy_first_model(my_second_model, parallel=True, name='merged_model')\nmy_first_model.print('./')\n</code></pre>\n\n<p>It will merge the two models into one single with two outputs if <code>parallel=True</code>, else it will be added at the bottom.</p>\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/iTzAlver/basenet_api/main/doc/multimedia/example_model2.png\">\n</p>\n\n<h4 id=\"obtaining-training-results-from-the-fitting-process\">Obtaining training results from the fitting process.</h4>\n\n<p>Once you train the model, you can get a <code>BaseNetResults</code> object with the training results. You can obtain the values from:</p>\n\n<pre><code>my_results = my_first_model.fit(0, epochs=6)\nlosses = my_results.get()\nprint(losses)\n\n#    &gt; {'loss': [1., 0.7, 0.6, 0.5, 0.4, 0.3], \n#       'val_loss': [1., 0.8, 0.7, 0.6, 0.5, 0.4]}\n</code></pre>\n\n<h2 id=\"whats-new\">What's new?</h2>\n\n<h3 id=\"010\">&lt; 0.1.0</h3>\n\n<ol>\n<li>BaseNetModel included.</li>\n<li>BaseNetDatabase included.</li>\n<li>BaseNetCompiler included.</li>\n<li>Inheritance from CorNetAPI project.</li>\n<li>Multi-processing fitting.</li>\n<li>Tensorboard launching.</li>\n</ol>\n\n<h3 id=\"020\">0.2.0</h3>\n\n<ol>\n<li>BaseNetResults included (working).</li>\n<li>Now the model is callable.</li>\n<li>Switched print to logging.</li>\n<li>Project documentation.</li>\n</ol>\n\n<h3 id=\"100-103\">1.0.0 - 1.0.3</h3>\n\n<ol>\n<li>Python packaging</li>\n<li>1.0.x: Upload bug solving.</li>\n</ol>\n\n<h3 id=\"110\">1.1.0</h3>\n\n<ol>\n<li>Functional package.</li>\n<li>PyPi indexing.</li>\n</ol>\n\n<h3 id=\"120\">1.2.0:</h3>\n\n<ol>\n<li>Loss results included in the BaseNetResults while multiprocessing.</li>\n<li>GPU auto set up to avoid TensorFlow memory errors.</li>\n<li>Method <code>BaseNetCompiler.set_up_devices()</code> configures the GPUs according to the free RAM to be used in the API.</li>\n</ol>\n\n<h3 id=\"130\">1.3.0</h3>\n\n<ol>\n<li>Included WindowDiff to the project scope.</li>\n</ol>\n\n<h3 id=\"140\">1.4.0</h3>\n\n<ol>\n<li>Solved python packaging problems.</li>\n<li>Included force stop callback in the <code>BaseNetModel.fit_stop()</code> method.</li>\n</ol>\n\n<h3 id=\"150\">1.5.0</h3>\n\n<ol>\n<li>BaseNetDatabase now has the attributes <code>BaseNetDatabase.size</code> and <code>BaseNetDatabase.distribution</code>.</li>\n<li>Solved forced stopping bugs with multiprocessing in the method <code>BaseNetDatabase.fit_stop()</code>.</li>\n<li><code>BaseNetModel._threshold()</code> private method now takes a set of outputs instead only one. \nThis was only for optimization.</li>\n<li>Solved wrong <code>BaseNetModel.recover()</code>.</li>\n<li><strong>Auto recover implemented</strong>, now <code>BaseNetModel.recover()</code> is a private method: <code>BaseNetModel._recover()</code>.\nNow the used does not need to recover it. <em>The model recovers by itself. -- Hans Niemann 2022.</em></li>\n</ol>\n\n<h3 id=\"cite-as\">Cite as</h3>\n\n<p>Please, cite this library as:</p>\n\n<pre><code>@misc{basenetapi,\n  title={CorNet: Correlation clustering solving methods based on Deep Learning Models},\n  author={A. Palomo-Alonso},\n  booktitle={PhD in TIC: Machine Learning and NLP.},\n  year={2022}\n}\n</code></pre>\n"}, {"fullname": "basenet._loss_functions.windowdiff", "modulename": "basenet._loss_functions.windowdiff", "type": "module", "doc": "<p></p>\n"}, {"fullname": "basenet._loss_functions.windowdiff.window_diff", "modulename": "basenet._loss_functions.windowdiff", "qualname": "window_diff", "type": "function", "doc": "<p>This function computes the WindowDiff of two segmentations with Tensorflow.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>a</strong>:  Hypothesis segmentation.</li>\n<li><strong>b</strong>:  Reference segmentation.</li>\n<li><strong>th</strong>:  Segmentation threshold.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>WindowDiff metric.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">a</span><span class=\"p\">:</span> <span class=\"n\">tensorflow</span><span class=\"o\">.</span><span class=\"n\">python</span><span class=\"o\">.</span><span class=\"n\">framework</span><span class=\"o\">.</span><span class=\"n\">ops</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">b</span><span class=\"p\">:</span> <span class=\"n\">tensorflow</span><span class=\"o\">.</span><span class=\"n\">python</span><span class=\"o\">.</span><span class=\"n\">framework</span><span class=\"o\">.</span><span class=\"n\">ops</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">th</span><span class=\"o\">=</span><span class=\"mf\">0.5</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler", "modulename": "basenet.compiler", "type": "module", "doc": "<p>The compiler.py file contains the BaseNetCompiler class.</p>\n\n<p>Available layers:</p>\n\n<pre><code>*   KERAS_LIST_LAYERS\n*   PREBUILT_LAYERS\n</code></pre>\n\n<p>Available loss functions:</p>\n\n<pre><code>*   KERAS_LOSSES\n*   PREBUILT_LOSSES\n</code></pre>\n\n<p>Available optimizers:</p>\n\n<pre><code>*   KERAS_OPTIMIZERS\n*   PREBUILT_OPTIMIZERS\n</code></pre>\n"}, {"fullname": "basenet.compiler.BaseNetCompiler", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler", "type": "class", "doc": "<p>The BaseNetCompiler is a custom compiler that takes the information about the network and compiles it with the given\nparameters.</p>\n\n<p>The BaseNetCompiler also allows the user to use a .yaml file to build the network with the following format:</p>\n\n<pre><code>compiler:\n  name: &lt;name of the model&gt;\n  input_shape:\n    - &lt;input shape of the model (I)&gt;\n    - &lt;input shape of the model (II)&gt;\n    - &lt;...&gt;\n  output_shape: &lt;output shape of the model&gt;\n\n  compile_options:\n    loss: &lt;tf.keras loss function name&gt;\n    optimizer: &lt;tf.keras optimizer name&gt;\n    metrics:\n      - &lt;tf.keras loss function name provided as a loss function&gt;\n      - &lt;'accuracy' is always a good metric to analyze&gt;\n\n  devices:\n    - &lt;your device type&gt;:\n        name: &lt;the name of your device in BaseNetCompiler.show_devs()&gt;\n        state: &lt;'Idle' for nothing, 'Train' for training&gt;\n\n    &lt;some device examples:&gt;\n    - cpu:\n        name: \"/device:CPU:0\"\n        state: \"Idle\"\n    - gpu:\n        name: \"/device:GPU:0\"\n        state: \"Train\"\n    - gpu:\n        name: \"/device:GPU:1\"\n        state: \"Idle\"\n    - gpu:\n        name: \"/device:GPU:2\"\n        state: \"Idle\"\n\n  layers:\n    - layer:\n        name: &lt;layer name in tf.keras.layers&gt;\n        shape:\n            - &lt;layer shape (I)&gt;\n            - &lt;layer shape (II)&gt;\n            - &lt;...&gt;\n        options:\n            - option:\n                name: &lt;the name of the option in tf.keras.layers.&lt;your layer name&gt; or\n                       \"{open}/{close}_pipeline\"&gt;\n                value: &lt;the value of the option in tf.keras.layers.&lt;your layer name&gt;&gt;\n\n    &lt;some layer examples:&gt;\n    - layer:\n        name: \"Flatten\"\n        shape:\n        options:\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 128\n        options:\n          - option:\n              name: \"activation\"\n              value: \"relu\"\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 64\n        options:\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 32\n        options:\n          - option:\n              name: \"activation\"\n              value: \"sigmoid\"\n\n    - layer:\n        name: \"open_pipeline\"\n        shape:\n        options:\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 32\n        options:\n          - option:\n              name: \"activation\"\n              value: \"sigmoid\"\n\n    - layer:\n        name: \"open_pipeline\"\n        shape:\n        options:\n\n    - layer:\n        name: \"Dense\"\n        shape:\n          - 32\n        options:\n          - option:\n              name: \"activation\"\n              value: \"sigmoid\"\n\n    - layer:\n        name: \"close_pipeline\"\n        shape:\n        options:\n</code></pre>\n\n<p>When open_pipeline is provided, the model creates a separate pipeline for the incoming layers. If more than one\nopen_pipeline is provided, more pipelines will be added. When close_pipeline is provided, a\ntf.keras.layers.Concatenate layer is added into the model to close all the previous models into the main pipeline.</p>\n\n<p>This compiler implements some TensorFlow functions to list the GPU devices.</p>\n"}, {"fullname": "basenet.compiler.BaseNetCompiler.__init__", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.__init__", "type": "function", "doc": "<p>Build the BaseNetCompiler class.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>io_shape</strong>:  Input-output shape [(input,), output].</li>\n<li><strong>compile_options: Dictionary of compiling options {loss: , optimizer: , metrics</strong>:  }.</li>\n<li><strong>devices: {device: role}. Consider calling</strong>:  BaseNetCompiler.show_devs().</li>\n<li><strong>layers: List of layers: {name: ( (shape,) , {'args'</strong>:  args} )}.</li>\n<li><strong>name</strong>:  Name of the model.</li>\n<li><strong>verbose</strong>:  Print state and errors in the BaseNetCompiler.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">io_shape</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span>,</span><span class=\"param\">\t<span class=\"n\">compile_options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">devices</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>,</span><span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;current_model&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "basenet.compiler.BaseNetCompiler.build_from_yaml", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.build_from_yaml", "type": "function", "doc": "<p>This function builds the BaseNetCompiler from a formatted .yaml file.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>path</strong>:  Path of the .yaml file with the compiler directives.</li>\n<li><strong>verbose</strong>:  Enables print debugging.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The compiler object of the class BaseNetCompiler.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;C:</span><span class=\"se\">\\\\</span><span class=\"s1\">Users</span><span class=\"se\">\\\\</span><span class=\"s1\">fract</span><span class=\"se\">\\\\</span><span class=\"s1\">Desktop</span><span class=\"se\">\\\\</span><span class=\"s1\">BaseNet-API</span><span class=\"se\">\\\\</span><span class=\"s1\">src</span><span class=\"se\">\\\\</span><span class=\"s1\">basenet</span><span class=\"se\">\\\\</span><span class=\"s1\">include</span><span class=\"se\">\\\\</span><span class=\"s1\">config</span><span class=\"se\">\\\\</span><span class=\"s1\">compilers</span><span class=\"se\">\\\\</span><span class=\"s1\">base_compiler.yaml&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.compile", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.compile", "type": "function", "doc": "<p>This method of the BaseNetCompiler generates a BaseNetModel from a valid BaseNetCompiler.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>name</strong>:  Name of the model. This variable overrides the name parameter of the BaseNetCompiler\nif it is provided.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>(BaseNetCompiler, BaseNetModel)</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.show_devs", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.show_devs", "type": "function", "doc": "<p>This method lists the devices in the current machine with the BaseNetModel dictionary format.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary with all the available devices in the machine.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.pop", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.pop", "type": "function", "doc": "<p>This method pops out a layer from the architecture.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>index</strong>:  The place of the layer in the layers list.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The popped layer.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">index</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.add", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.add", "type": "function", "doc": "<p>This function adds a new layer on the bottom of the architecture.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>layer</strong>:  The layer to be added to the compiler.</li>\n<li><strong>where</strong>:  The place to be inserted in the architecture.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Bypasses the current BaseNetCompiler.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">layer</span><span class=\"p\">:</span> <span class=\"nb\">dict</span>, </span><span class=\"param\"><span class=\"n\">where</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.save", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.save", "type": "function", "doc": "<p>This function saves the BaseNetCompiler in a .cpl format.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>_compiler_path</strong>:  Path where the BaseNetCompiler is being saved in the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the saving was successful. False if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">_compiler_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.export", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.export", "type": "function", "doc": "<p>This function export the BaseNetCompiler to a .yaml format.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>_compiler_path</strong>:  Path where the BaseNetCompiler .yaml file is being saved in the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the saving was successful. False if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">_compiler_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.load", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.load", "type": "function", "doc": "<p>This function loads a BaseNetCompiler from a .cpl file format.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>_compiler_path</strong>:  Path where the BaseNetCompiler is being loaded from the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The BaseNetCompiler if the saving was successful. 'None' if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">_compiler_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.compiler.BaseNetCompiler.set_up_devices", "modulename": "basenet.compiler", "qualname": "BaseNetCompiler.set_up_devices", "type": "function", "doc": "<p>This function automatically sets the available devices for use in the models.\nNote that if your free VRAM &gt; free RAM the TF framework will report OUT_OF_MEMORY errors.\nThis function disables some GPUs from the Python scope.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>let_free_ram</strong>:  The percentage of RAM not to be used.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Nothing, this function just sets up an internal API config file.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">let_free_ram</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.8</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.database", "modulename": "basenet.database", "type": "module", "doc": "<p>The database.py file contains the BaseNetDatabase class.</p>\n"}, {"fullname": "basenet.database.BaseNetDatabase", "modulename": "basenet.database", "qualname": "BaseNetDatabase", "type": "class", "doc": "<p>The BaseNetDatabase class converts a set of inputs (x) and solutions (y) into the API wrapper database.\nThe BaseNetDatabase will create a new set of attributes from the database randomly:</p>\n\n<pre><code>*   xtrain: A subset of (x) with the train inputs of the network.\n*   ytrain: A subset of (y) with the train solutions of the network.\n*   xval: A subset of (x) with the training validation inputs of the network.\n*   yval: A subset of (y) with the training validation solutions of the network.\n*   xtest: A subset of (x) with excluded inputs of the network; for future testing.\n*   ytest: A subset of (y) with excluded solutions of the network; for future testing.\n\n*   dtype: Data type of the input data (x) and output data (y) in a tuple of strings (x_dtype, y_dtype).\n*   name: Name of the database.\n*   distribution: Train, validation and test distribution of the input database.\n*   batch_size: Current batch size of the database.\n*   size: The size of the database (train, validation , test).\n</code></pre>\n\n<p>The BaseNetDatabase can be loaded and saved with its own methods.</p>\n"}, {"fullname": "basenet.database.BaseNetDatabase.__init__", "modulename": "basenet.database", "qualname": "BaseNetDatabase.__init__", "type": "function", "doc": "<p>This class builds a BaseNetDatabase, compatible with the NetBase API.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong>:  Inputs of the dataset.</li>\n<li><strong>y</strong>:  Solutions of the dataset.</li>\n<li><strong>distribution: The distribution of the datasets, default: {'train': 70, 'val': 20, 'test'</strong>:  10}</li>\n<li><strong>name</strong>:  The database name.</li>\n<li><strong>batch_size</strong>:  Custom batch size for training.</li>\n<li><strong>rescale</strong>:  Rescale factor, all the values in x are divided by this factor, in case rescale is needed.</li>\n<li><strong>dtype</strong>:  Data type of the dataset. ('input', 'output') (x, y)</li>\n<li><strong>bits</strong>:  Bits used for the data type. ('input', 'output') (x, y)</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">x</span>,</span><span class=\"param\">\t<span class=\"n\">y</span>,</span><span class=\"param\">\t<span class=\"n\">distribution</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;unnamed_database&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">rescale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">&#39;float&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;float&#39;</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">bits</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)</span></span>)</span>"}, {"fullname": "basenet.database.BaseNetDatabase.load", "modulename": "basenet.database", "qualname": "BaseNetDatabase.load", "type": "function", "doc": "<p>This function loads the BaseNetDatabase from any path.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>path</strong>:  Path where the BaseNetDatabase is being saved in the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The loaded database if successful. 'None' if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.database.BaseNetDatabase.save", "modulename": "basenet.database", "qualname": "BaseNetDatabase.save", "type": "function", "doc": "<p>This function saves the BaseNetDatabase in any format.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>path</strong>:  Path where the BaseNetDatabase is being saved in the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the saving was successful. False if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model", "modulename": "basenet.model", "type": "module", "doc": "<p>The model.py file includes the BaseNetModel class and the BaseNetResults class.</p>\n"}, {"fullname": "basenet.model.BaseNetModel", "modulename": "basenet.model", "qualname": "BaseNetModel", "type": "class", "doc": "<p>The BaseNetModel class provides a wrapper for the tf.keras.model API with easier use. When initialized,\nit initializes a breech of databases in its attribute 'breech'. If we provide a compiler, the model will be\nbuilt from the compiler; however, if we provide a tf.keras.model, the compiler is ignored and the model is built\nfrom the provided tf.keras.model.</p>\n\n<p>To add a database to the model, we can use the method BaseNetModel.add_database() that takes a BaseNetDatabase as\ninput.</p>\n\n<p>The class contains load and save methods to store the compilers (.cpl files) and models (.h5 files) in the same\ndirectory.</p>\n\n<p>We also provide a BaseNetModel.fit() method that can create a separate process for training. The original framework\ndoes not include this feature:</p>\n\n<ul>\n<li>The BaseNetModel.fit() method takes as input the index of the loaded database via\nBaseNetModel.add_database() method and takes the train and validation subsets to fit the model.</li>\n<li>If the training process should not block the main process, the parameters 'avoid_lock' must be set to True,\nin that case, another process will take over the fitting tf.keras.model.fit() method and the information will\nbe updated in the return class: BaseNetResults.</li>\n<li>In case we avoid the main process to be locked with the 'avoid_lock' feature, we will need to recover the\ntf.keras.model with the BaseNetModel.recover() method once the training is finished (check\nBaseNetResults.is_training).</li>\n</ul>\n\n<p>We can also evaluate the performance of the database with the BaseNetModel.evaluate() method, that makes use of the\ntest subset.</p>\n\n<p>We can also predict the output of a certain input with the BaseNetModel.predict() method.</p>\n\n<p>We can also visualize the model with the BaseNetModel.print() method in a PNG image.</p>\n\n<p>The following attributes can be found in a regular <code>BaseNetModel</code>:</p>\n\n<ul>\n<li>:compiler:: It is the given compiler (BaseNetCompiler).</li>\n<li>:is_valid:: Tells if a model is valid or not (bool).</li>\n<li>:is_compiled:: Tells if a model is compiled or not (bool).</li>\n<li>:name:: The name of the model (str).</li>\n<li>:breech:: The list of the loaded databases (list[BaseNetDatabase]).</li>\n<li>:model:: It is the compiled keras model (tf.keras.model).</li>\n<li>:summary:: The tf.keras.model information (str).</li>\n</ul>\n"}, {"fullname": "basenet.model.BaseNetModel.__init__", "modulename": "basenet.model", "qualname": "BaseNetModel.__init__", "type": "function", "doc": "<p>The BaseNetModel implements an API that makes use of keras and tensorflow to build Deep Learning Models.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>compiler</strong>:  BaseNetCompiler object to build the model.</li>\n<li><strong>model</strong>:  If a keras.model is already compiled, you can import it in the model parameter, so the compiler\nwon't be used during the construction.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">compiler</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">engine</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">Model</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span>)</span>"}, {"fullname": "basenet.model.BaseNetModel.fit", "modulename": "basenet.model", "qualname": "BaseNetModel.fit", "type": "function", "doc": "<p>This function fits the BaseNetModel with the selected database.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ndb</strong>:  Index of the database already loaded. The default is the last database.</li>\n<li><strong>epochs</strong>:  Number of epochs to train. It is 10 by default.</li>\n<li><strong>tensorboard</strong>:  Activates or deactivates the Tensorboard.</li>\n<li><strong>avoid_lock</strong>:  Avoids the training process to lock the parent process.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>BaseNetResults of the fitting process.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">ndb</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">tensorboard</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">avoid_lock</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.predict", "modulename": "basenet.model", "qualname": "BaseNetModel.predict", "type": "function", "doc": "<p>This function predicts with the current model an output from the input 'x', divided by the 'scale' and converted\nto a binary matrix with a custom threshold 'th'.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong>:  Input np.array o tf.Tensor.</li>\n<li><strong>scale: Divides by a custom scale (default</strong>:  255.0 -> 8bit images).</li>\n<li><strong>th: Custom output threshold (default</strong>:  0.5 -> mid-range predictions). Set up to 'None' to see\nthe real output.</li>\n<li><strong>expand_dims</strong>:  Expands the dimension of the tensor.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The prediction output of the model.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span>,</span><span class=\"param\">\t<span class=\"n\">scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\tth: (None, &lt;class &#x27;float&#x27;&gt;) = 0.5,</span><span class=\"param\">\t<span class=\"n\">expand_dims</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">tensorflow</span><span class=\"o\">.</span><span class=\"n\">python</span><span class=\"o\">.</span><span class=\"n\">framework</span><span class=\"o\">.</span><span class=\"n\">ops</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.evaluate", "modulename": "basenet.model", "qualname": "BaseNetModel.evaluate", "type": "function", "doc": "<p>This method evaluates the test dataset of a BaseNetDatabase.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ndb</strong>:  Number of the database to be tested.</li>\n<li><strong>metric</strong>:  A metric function.</li>\n<li><strong>th</strong>:  The threshold of the prediction, if not None.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The evaluated metric.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">ndb</span>,</span><span class=\"param\">\t<span class=\"n\">metric</span>,</span><span class=\"param\">\tth: (None, &lt;class &#x27;float&#x27;&gt;) = 0.5</span><span class=\"return-annotation\">) -> (&lt;class &#x27;tensorflow.python.framework.ops.Tensor&#x27;&gt;, None):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.add_database", "modulename": "basenet.model", "qualname": "BaseNetModel.add_database", "type": "function", "doc": "<p>This method adds a database into the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>db</strong>:  A BaseNetDatabase.</li>\n<li><strong>db_path</strong>:  A path to a BaseNetDatabase.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The same object.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\tdb: (&lt;class &#x27;basenet.database.BaseNetDatabase&#x27;&gt;, None, &lt;class &#x27;str&#x27;&gt;) = None,</span><span class=\"param\">\t<span class=\"n\">db_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.save", "modulename": "basenet.model", "qualname": "BaseNetModel.save", "type": "function", "doc": "<p>This function saves the BaseNetModel in a pair: .cpl (BaseNetCompiler) and .h5 (keras.model) format.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_path</strong>:  Path where the keras.model is being saved in the file system.</li>\n<li><strong>compiler_path</strong>:  Path where the BaseNetCompiler is being saved in the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if the saving was successful. False if not.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">compiler_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">bool</span>:</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.load", "modulename": "basenet.model", "qualname": "BaseNetModel.load", "type": "function", "doc": "<p>This function loads a pair: .cpl (BaseNetCompiler) and .h5 (keras.model) format and builds a BaseNetModel from\nthe loaded parameters.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_path</strong>:  Path where the keras.model is being loaded from the file system.</li>\n<li><strong>compiler_path</strong>:  Path where the BaseNetCompiler is being loaded from the file system.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The BaseNetModel with the given model path.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">compiler_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.print", "modulename": "basenet.model", "qualname": "BaseNetModel.print", "type": "function", "doc": "<p>This function renders an image with the architecture of the compiled model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>print_path</strong>:  Path where the image of the model is saved.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A bypass of the current object.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">print_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;C:</span><span class=\"se\">\\\\</span><span class=\"s1\">Users</span><span class=\"se\">\\\\</span><span class=\"s1\">fract</span><span class=\"se\">\\\\</span><span class=\"s1\">Desktop</span><span class=\"se\">\\\\</span><span class=\"s1\">BaseNet-API</span><span class=\"se\">\\\\</span><span class=\"s1\">src</span><span class=\"se\">\\\\</span><span class=\"s1\">basenet</span><span class=\"se\">\\\\</span><span class=\"s1\">include</span><span class=\"se\">\\\\</span><span class=\"s1\">temp/render/&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.recover", "modulename": "basenet.model", "qualname": "BaseNetModel.recover", "type": "function", "doc": "<p>This functions recovers the model from a training when the option 'avoid_lock == True'.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>True if there was a recover. False if there was not a recover or an exception raised.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.call", "modulename": "basenet.model", "qualname": "BaseNetModel.call", "type": "function", "doc": "<p>When calling the class BaseNetModel, you can merge two different models. So the model1(model2) will merge the\nmodel2 into the model1. By default, all the model parameters and options are inherited from the model1.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>args</strong>:  Incoming model; BaseNetModel or tf.keras.model.</li>\n<li><strong>kwargs: {'name'</strong>:  the model name; inherits the model1 name by default,\n'parallel': True for separate inputs, False to be sequential; False by default,\n'options': compile options; inherits the model1 compile options by default}</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A bypass of the current object.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetModel.fit_stop", "modulename": "basenet.model", "qualname": "BaseNetModel.fit_stop", "type": "function", "doc": "<p>The fit_stop method stops the current training process.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>It returns True if the fitting process finished; or False if there was no training process.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">task</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "basenet.model.BaseNetResults", "modulename": "basenet.model", "qualname": "BaseNetResults", "type": "class", "doc": "<p>The class BaseNetResults is a data collector of a training process. Using the get() method you update the\n.is_training attribute and collect the information of the training process. If you are training in a separate\nprocess, consider using this structure in your code:</p>\n\n<pre><code>results = my_basenet_model.fit(*args, **kwargs)\nwhile results.is_training:\n    do_my_main_task()\n    results_in_a_dictionary = results.get()\nmy_basenet_model.recover()\n\nkeep_doing_my_main_task()\n</code></pre>\n\n<p>You can only acces the attribute BaseNetResults.is_training and BaseNetResults.get()</p>\n"}, {"fullname": "basenet.model.BaseNetResults.__init__", "modulename": "basenet.model", "qualname": "BaseNetResults.__init__", "type": "function", "doc": "<p>The BaseNetResults constructor should not be used by the default user.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>loss</strong>:  __inner parameter__</li>\n<li><strong>val_loss</strong>:  __inner parameter__</li>\n<li><strong>queue</strong>:  __inner parameter__</li>\n<li><strong>parent</strong>:  __inner parameter__</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">val_loss</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">queue</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">bound</span> <span class=\"n\">method</span> <span class=\"n\">BaseContext</span><span class=\"o\">.</span><span class=\"n\">Queue</span> <span class=\"n\">of</span> <span class=\"o\">&lt;</span><span class=\"n\">multiprocessing</span><span class=\"o\">.</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">DefaultContext</span> <span class=\"nb\">object</span> <span class=\"n\">at</span> <span class=\"mh\">0x000002B42E20A460</span><span class=\"o\">&gt;&gt;</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">parent</span><span class=\"p\">:</span> <span class=\"n\">multiprocessing</span><span class=\"o\">.</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">Process</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "basenet.model.BaseNetResults.get", "modulename": "basenet.model", "qualname": "BaseNetResults.get", "type": "function", "doc": "<p>The get() method obtains the results from the training process.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A dictionary with the training and validation losses. {'loss': [], 'val_loss': []}</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();